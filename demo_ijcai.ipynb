{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import ray\n",
    "\n",
    "\n",
    "from app.utils import unwrap_angles, calculate_euler_angles_list\n",
    "from hyperopt import hp\n",
    "from ray import tune\n",
    "from sklearn.model_selection import KFold\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from app.workflow.utils import calculate_score_between, add_predicted_transitions_to_df, calculate_scores_sec_metric, calculate_overall_score, align_min_max_lists_counts_order, get_score_for_intervals, process_turns_with_restricted_distances, find_midpoints_with_weights, find_midpoints, align_min_max_lists, label_apex_list, label_apex, filter_extremes, read_files_recursive, read_files, split_data_granular, smooth_data, remove_outliers, merge_close_integers, find_closest_actuals, find_tp_fp_fn_tn, calculate_performance_metrics, append_predictions_df_new\n",
    "from app.workflow.gradientdescent import gradient_descent_full\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data = read_files_recursive(path = \"data\")\n",
    "split_on = \"Orientation\"\n",
    "orientation_dfs = split_data_granular(labeled_data, split_on=split_on)\n",
    "transformed_dfs = calculate_euler_angles_list(orientation_dfs)\n",
    "unwraped_data = unwrap_angles(transformed_dfs)\n",
    "smoothed_orientation_dfs = smooth_data(unwraped_data, window_size=10)\n",
    "apex_dfs = label_apex_list(smoothed_orientation_dfs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define ray function to run algorithm\n",
    "#### mode is used to define application for algorithm.  \n",
    "#### mode = \"between\", \"apex_percentage\", \"turn_coverage\" response for use cases presented in pdf in the same order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_combination_ray(combination, train, col= \"yaw\", random_seed = 42, mode = \"regular\", detail_metric = False):\n",
    "    if mode != \"regular\" and mode != \"between\" and mode != \"apex_percentage\" and mode != \"turn_coverage\":\n",
    "        raise ValueError(\"Mode must be 'regular' or 'between'\")\n",
    "    combination[\"Gradient_Steps\"] = int(combination[\"Gradient_Steps\"])\n",
    "    combination[\"merge_threshold\"] = int(combination[\"merge_threshold\"])\n",
    "    combination[\"number_of_points\"] = int(combination[\"number_of_points\"])\n",
    "    combination[\"Threshold\"] = int(combination[\"Threshold\"])\n",
    "    np.random.seed(random_seed)  # Set the random seed inside the remote function\n",
    "\n",
    "    total_TP = []\n",
    "    total_FP = []\n",
    "    total_FN = []\n",
    "    total_TN = []\n",
    "\n",
    "\n",
    "    total_int_TP = 0\n",
    "    total_int_FP = 0\n",
    "    total_int_FN = 0\n",
    "    total_int_TN = 0\n",
    "\n",
    "    # *for metrics apex percentage and turn coverage\n",
    "    total_score = 0\n",
    "    total_lenght = 0\n",
    "    for df in train:\n",
    "        start_indices = np.random.randint(1, len(df), size=combination[\"number_of_points\"])\n",
    "\n",
    "        predicted_mins, predicted_maxs = gradient_descent_full(df, start_indices, learning_rate=combination['Gradient_LR'], steps=combination[\"Gradient_Steps\"], momentum=combination['Gradient_Momentum'], selected_col= col, printing=False)\n",
    "\n",
    "        unique_predictions_mins, counts_mins = np.unique(predicted_mins, return_counts=True)\n",
    "        unique_predictions_maxs, counts_maxs = np.unique(predicted_maxs, return_counts=True)\n",
    "\n",
    "        new_mins, new_counts_min = merge_close_integers(unique_predictions_mins, counts_mins, threshold = combination['merge_threshold'])\n",
    "        new_max, new_counts_max = merge_close_integers(unique_predictions_maxs, counts_maxs, threshold = combination['merge_threshold'])\n",
    "\n",
    "        new_filtered_mins, new_filtered_mins_counts = remove_outliers(new_mins, new_counts_min, df, multiplier= combination['outliers_multiplier'], selected_col=col, boundary=\"upper\")\n",
    "        new_filtered_max, new_filtered_maxs_counts = remove_outliers(new_max, new_counts_max, df, combination['outliers_multiplier'], selected_col=col, boundary=\"lower\")\n",
    "\n",
    "        important_min, important_min_counts = filter_extremes(new_filtered_mins, new_filtered_mins_counts,threshold_int=combination['Threshold'])\n",
    "        important_max, important_max_counts = filter_extremes(new_filtered_max, new_filtered_maxs_counts,threshold_int=combination['Threshold'])\n",
    "        \n",
    "        if mode == \"regular\":\n",
    "            trimmed_mins, trimmed_mins_counts, trimmed_maxs, trimmed_maxs_counts = align_min_max_lists(important_min, important_min_counts, important_max, important_max_counts)\n",
    "            new_trimed_mins, new_trimed_maxs = find_midpoints(trimmed_mins, trimmed_maxs)\n",
    "            \n",
    "            df_forecast = append_predictions_df_new(df, new_trimed_mins, new_trimed_maxs) \n",
    "            df_forecast_closest = find_closest_actuals(df_forecast)\n",
    "\n",
    "            df_TP, df_FP, df_FN, tn, custom_score = find_tp_fp_fn_tn(df_forecast=df_forecast_closest, margin_of_error = 10)\n",
    "            total_TP.append(df_TP)\n",
    "            total_FP.append(df_FP)\n",
    "            total_FN.append(df_FN)\n",
    "            total_TN.append(tn)\n",
    "        elif mode == \"between\": # 1st metric\n",
    "            trimmed_mins, trimmed_mins_counts, trimmed_maxs, trimmed_maxs_counts = align_min_max_lists(important_min, important_min_counts, important_max, important_max_counts)\n",
    "            new_trimed_mins, new_trimed_maxs = find_midpoints(trimmed_mins, trimmed_maxs)\n",
    "            \n",
    "            df_forecast = append_predictions_df_new(df, new_trimed_mins, new_trimed_maxs) \n",
    "            df_forecast_closest = find_closest_actuals(df_forecast)\n",
    "            \n",
    "            int_TP, int_FP, int_FN, int_tn = calculate_score_between(df_forecast=df_forecast_closest)\n",
    "            total_int_TP += int_TP\n",
    "            total_int_FP += int_FP\n",
    "            total_int_FN += int_FN\n",
    "            total_int_TN += int_tn\n",
    "        elif mode == \"apex_percentage\": # 2nd metric\n",
    "            trimmed_mins, trimmed_mins_counts, trimmed_maxs, trimmed_maxs_counts = align_min_max_lists(important_min, important_min_counts, important_max, important_max_counts)\n",
    "            new_trimed_mins, new_mins_counts, new_trimed_maxs, new_max_counts = find_midpoints_with_weights(trimmed_mins, trimmed_mins_counts, trimmed_maxs, trimmed_maxs_counts)\n",
    "            \n",
    "            df_forecast = append_predictions_df_new(df, new_trimed_mins, new_trimed_maxs, new_mins_counts, new_max_counts) \n",
    "            df_forecast_closest = find_closest_actuals(df_forecast)\n",
    "            \n",
    "            inv_df = process_turns_with_restricted_distances(df_forecast_closest)\n",
    "            score_df = calculate_scores_sec_metric(inv_df)\n",
    "            df_scores_sum, df_lenghts = calculate_overall_score(score_df)\n",
    "            total_score += df_scores_sum\n",
    "            total_lenght += df_lenghts\n",
    "        \n",
    "        elif mode == \"turn_coverage\": # 3rd metric\n",
    "            new_method_mins, new_method_max = align_min_max_lists_counts_order(important_min, important_max, important_min_counts, important_max_counts)\n",
    "            inteval_df = add_predicted_transitions_to_df(df, new_method_mins, new_method_max)\n",
    "            df_scores_sum, df_lenghts = get_score_for_intervals(inteval_df)\n",
    "            total_score += df_scores_sum\n",
    "            total_lenght += df_lenghts\n",
    "            \n",
    "\n",
    "\n",
    "    if mode == \"regular\":\n",
    "        total_TP_rows = sum(len(df) for df in total_TP)\n",
    "        total_FP_rows = sum(len(df) for df in total_FP)\n",
    "        total_FN_rows = sum(len(df) for df in total_FN)\n",
    "        total_TN_num = sum(total_TN)\n",
    "        metrics = calculate_performance_metrics(total_TP_rows, total_FP_rows, total_FN_rows, total_TN_num)\n",
    "        return metrics['Overall F1 Score']\n",
    "\n",
    "    elif mode == \"between\":\n",
    "        metrics = calculate_performance_metrics(total_int_TP, total_int_FP, total_int_FN, total_int_TN)\n",
    "        if detail_metric:\n",
    "            return metrics\n",
    "        return metrics['Overall F1 Score']\n",
    "    elif mode == \"apex_percentage\":\n",
    "        return total_score/total_lenght\n",
    "    elif mode == \"turn_coverage\":\n",
    "        return total_score/total_lenght\n",
    "\n",
    "\n",
    "def calculate_score_train(config, train):\n",
    "\n",
    "\n",
    "    score = process_combination_ray(config, train, \"yaw\", 42, \"regular\") #between\n",
    "\n",
    "    tune.report(score=score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define search space for algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_values(start, stop, step):\n",
    "    return list(range(start, stop + 1, step))\n",
    "\n",
    "\n",
    "gradient_lr_range = (0.01, 0.1)\n",
    "gradient_steps_range = (100, 500) \n",
    "gradient_steps_step = 10  \n",
    "momentum_range = (0.90, 0.999)\n",
    "merge_threshold_range = (5, 20) \n",
    "outliers_range = (2.0, 5.0)\n",
    "number_of_points_range = (100, 1000)  \n",
    "number_of_points_step = 100 \n",
    "threshold_range = (0, 20) \n",
    "\n",
    "\n",
    "gradient_steps_values = generate_values(gradient_steps_range[0], gradient_steps_range[1], gradient_steps_step)\n",
    "number_of_points_values = generate_values(number_of_points_range[0], number_of_points_range[1], number_of_points_step)\n",
    "\n",
    "space = {\n",
    "    'Gradient_LR': hp.loguniform('Gradient_LR', np.log(gradient_lr_range[0]), np.log(gradient_lr_range[1])),\n",
    "    'Gradient_Steps': hp.choice('Gradient_Steps', gradient_steps_values),  \n",
    "    'Gradient_Momentum': hp.uniform('Gradient_Momentum', *momentum_range),  \n",
    "    'merge_threshold': hp.randint('merge_threshold', merge_threshold_range[1] - merge_threshold_range[0]) + merge_threshold_range[0], \n",
    "    'outliers_multiplier': hp.uniform('outliers_multiplier', *outliers_range), \n",
    "    'number_of_points': hp.choice('number_of_points', number_of_points_values),  \n",
    "    'Threshold': hp.randint('Threshold', threshold_range[1] - threshold_range[0]) + threshold_range[0] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a cross-validation wrapper\n",
    "def calculate_score_cv(config, train, n_splits=5, random_seed=42):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(train):\n",
    "        # Split data into train and validation folds\n",
    "        train_fold = [train[i] for i in train_index]\n",
    "        val_fold = [train[i] for i in val_index]\n",
    "\n",
    "        np.random.seed(random_seed) \n",
    "\n",
    "        #* choose metric from: between, apex_percentage, turn_coverage\n",
    "        # Train on the train_fold\n",
    "        process_combination_ray(config, train_fold, \"yaw\", random_seed, \"between\")\n",
    "\n",
    "        # Evaluate on the val_fold\n",
    "        val_score = process_combination_ray(config, val_fold, \"yaw\", random_seed, \"between\")\n",
    "        f1_scores.append(val_score)\n",
    "\n",
    "    # Calculate mean F1 score across all folds\n",
    "    mean_f1_score = np.mean(f1_scores)\n",
    "\n",
    "    # Report the mean score for this configuration\n",
    "    tune.report(score=mean_f1_score)\n",
    "\n",
    "# Initialize Ray\n",
    "random_seed = 42\n",
    "train, test = train_test_split(apex_dfs, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "ray.init()\n",
    "#ray.init(log_to_driver=False)\n",
    "\n",
    "# Trainable with cross-validation\n",
    "trainable_with_cv = lambda config: calculate_score_cv(config, train)\n",
    "\n",
    "# Define the HyperOptSearch\n",
    "hyperopt_search = HyperOptSearch(\n",
    "    metric=\"score\",  # Target metric\n",
    "    mode=\"max\",      # Optimization mode\n",
    "    space=space,      # Search space\n",
    "    random_state_seed = random_seed\n",
    ")\n",
    "\n",
    "experiment_name = \"test\"\n",
    "\n",
    "analysis = tune.run(\n",
    "    trainable_with_cv,\n",
    "    search_alg=hyperopt_search,\n",
    "    num_samples=50,\n",
    "    resources_per_trial={\"cpu\": 1},\n",
    "    metric=\"score\",\n",
    "    mode=\"max\",\n",
    "    local_dir=\"./ray_results\", \n",
    "    name=experiment_name,        # Use a fixed folder name for the experiment\n",
    "    keep_checkpoints_num=3,     \n",
    "    resume=\"AUTO\",              \n",
    ")\n",
    "\n",
    "\n",
    "# Shutdown Ray\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on the train set\n",
    "best_config = analysis.best_config\n",
    "final_score = process_combination_ray(best_config, train, \"yaw\", random_seed, \"between\", detail_metric=False)\n",
    "\n",
    "# Evaluate final model on the test set\n",
    "test_score = process_combination_ray(best_config, test, \"yaw\", random_seed, \"between\", detail_metric=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "again_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
